### Augmenting large language models with chemistry tools
From: [Augmenting large language models with chemistry tools | OpenReview](https://openreview.net/forum?id=wdGIL6lx3l)  
Code: [GitHub - ur-whitelab/chemcrow-public: Chemcrow](https://github.com/ur-whitelab/chemcrow-public)
#### 基本
**通过结合外部工具克服不足**
通过各个实验结果，专家化训练的大模型具备一定的化学理解能力，指：
- adapting to observations  适应观察结果
- planning over multipe steps  多步规划
- responding correctly to intent 正确响应意图
但是面临着一些问题：
- 化学的高度实验性
- 数据缺少
- 化学工具的有限应用
#### chemCrow
任务解决：
1. 基于化学工具（软件和包），创建一组工具。
2. 输入工具和用户指令
3. LLM自动化迭代，决定路径，工具和输入，得出答案
给工具名称和用途，预期输入输出详细信息 -- LLM(GPT-4)指示使用必要的工具回答用户的提示(prompt)   
具体实现遵循*Thought，Action，Action Input(keyword)* 然后文本输出停止，由程序调用函数执行结果？将结果返回给LLM，作为*Observation*，然后迭代  
LLM这里变成一个推理引擎，chemCrow部署在云端，可以通过自然语言（应该还有应用的部署）增添新的应用(工具)。
#### 评估
不是很明白在做什么  
好像是拿GPT4和人类作为专家评估chemCrow和GPT4的化学任务解决能力。  
目的可能在于：  
	*“GPT-4最近被提出并用作自我评估方法，但这些结果表明，当它缺乏回答问题所需的理解时，它也缺乏评估问题完成的信息，因此无法提供可信的评估，使其在评估LLM能力的基准测试中无法使用，尤其是在事实性发挥关键作用的情况下“*
#### 安全
- 继续进行任务之前检查安全信息
- 更广泛的数据集和高级化学知识（大概是没用的话）
#### 此外
- 闭源模型提供了有限的控制(API)，开源有更多的可能性
- LangChain 80
- WebSearch，利用SerpAPI查询搜索引擎
- LitSearch，文献搜索工具，利用*paper-qa*包 ([Page not found · GitHub · GitHub](https://github.com/whitead/paperqa)) ，通过*OpenAI Embeddings*和*FAISS*这两个工具嵌入和搜索(供LLM使用)
- python REPL：Langchain标准工具，提供了一个功能齐备的python shell，使LLM可以直接编写和运行python代码
- 和一些其他专门的化学工具