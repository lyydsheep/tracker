# 从零入门炼丹师

## 2、PyTorch2.0 深度学习环境搭建

#### 2.1.3计算Softmax函数

$$\sigma(z_i) = \frac{e^{z_{i}}}{\sum_{j=1}^K e^{z_{j}}} \ \ \ for\ i=1,2,\dots,K$$

```python
#一维
def softmax(inMatrix):
    m, n = np.shape(inMatrix)
    outMatrix = np.mat(np.zeros(m, n))
    softSum = 0
    for i in range(0, n):
        outMatrix[0, i] = np.exp(inMatrix[0, i])
        softSum += outMatrix[0, i]
    for i in range(0, n):
        outMatrix[0, i] /= softSum
    return outMatrix
```

## 3、PyTorch学习

one_hot函数：将一个序列转换成以one_hot形式表示的数据集合。所有的行或列都被设置为0，只有若干个特定的位置用1来表示

```python
torch.nn.functional.one_hoe(x, num)
#一个参数张量x，num为类别数
```

[深入浅出 one-hot - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/634296763)

CrossEntropyLoss，交叉熵损失函数用于训练一个单标签或者多标签类别的分类问题
